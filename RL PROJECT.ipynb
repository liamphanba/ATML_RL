{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **RL PROJECT** - **DICE GAME**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The Game"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we consider the following “Dice Game”. The objective of the game is to make money by\n",
    "outscoring the dealer or by rolling doubles. Each round, the player starts with a score of zero. Since this\n",
    "is an episodic task, discounting is not necessary.\n",
    "\n",
    "Each turn, the player has to choose between rolling their dice, or betting money on the dealer’s roll. If\n",
    "they decide to roll themselves, they can either roll one or two dice (simultaneously), which costs them\n",
    "CHF 1 for one dice, and CHF 2 for two dice. The number(s) shown by the dice are added to the player’s\n",
    "score. If the player rolls a double (i.e., two dice showing the same numbers), they get an immediate\n",
    "bonus payout of CHF 10, independent of the rest of the game or their score. If the player reaches a\n",
    "score of 31 or more, they lose the round and have to pay CHF 10.\n",
    "\n",
    "If the player chooses to bet on the dealer’s roll, they have to specify a bet-multiplicator of 1, 2, or 3. The\n",
    "dealer then rolls their dice and the player is paid/has to pay according to the formula\n",
    "(“Player Score” −“Dealer Dice Result”) ·“Bet-Multiplicator”,\n",
    "and the round is over\n",
    "\n",
    "The player has two identical dice, showing the numbers {1,2,3,4,5,6}. The dealer has one dice,\n",
    "showing the numbers {25,26,27,28,29,30}. All three dice are weighted, such that their highest\n",
    "number has twice the probability of each of the smaller numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FlowChart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. The Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Throughout, the state space should have (at most) one terminal state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Considering the game as a Markov decision process, identify the state space S, the action\n",
    "space A, and the reward set R."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Implement a Python class that represents the game as a reinforcement learning task. The class\n",
    "should contain all the information about the game state, and should provide a “step” method that\n",
    "takes an action as input and returns the reward and next state, as well as a “reset” method that\n",
    "resets the game to its initial state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Using dynamic programming, compute the value functions under the following policies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Find the optimal policy using dynamic programming. Represent the action-value function under\n",
    "the optimal policy graphically. Explain the results and compare them to those of the previous task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BONUS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the class you implemented in the first task for the following Monte Carlo simulation: estimate\n",
    "the value of the initial state under each of the policies from the previous tasks (“R1”, “R2”, “RR”,\n",
    "“Optimal”). Illustrate the results and compare them to the results of the previous tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
